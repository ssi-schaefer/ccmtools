// $ANTLR 2.7.2: "dtd.g" -> "DtdParser.java"$

/*
 * This file was automatically generated by
 * 'ANTLR Translator Generator' (http://www.antlr.org).
 *
 * DO NOT EDIT!
 */


/* DTD parser
 *
 * 2003 by Robert Lechner (rlechner@gmx.at)
 *
 * $Id$
 *
 * This library is free software; you can redistribute it and/or modify it under
 * the terms of the GNU Lesser General Public License as published by the Free
 * Software Foundation; either version 2.1 of the License, or (at your option)
 * any later version.
 *
 * This library is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
 * FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more
 * details.
 *
 * You should have received a copy of the GNU Lesser General Public License
 * along with this library; if not, write to the Free Software Foundation, Inc.,
 * 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 */

package ccmtools.dtd2java;

import antlr.TokenBuffer;
import antlr.TokenStreamException;
import antlr.TokenStreamIOException;
import antlr.ANTLRException;
import antlr.LLkParser;
import antlr.Token;
import antlr.TokenStream;
import antlr.RecognitionException;
import antlr.NoViableAltException;
import antlr.MismatchedTokenException;
import antlr.SemanticException;
import antlr.ParserSharedInputState;
import antlr.collections.impl.BitSet;

public class DtdParser extends antlr.LLkParser       implements DTDTokenTypes
 {

	/**
	 * Reads a DTD-file and creates the parse tree.
	 * Writes the preprocessed DTD to "fileName.PP.dtd".
	 *
	 * @param fileName  the name of the DTD-file
	 * @return the parse tree
	 *
	 * @throws java.io.IOException  file I/O error
	 * @throws antlr.ANTLRException  parser error
	 */
	public static DtdFile parseFile( String fileName )
	 throws antlr.ANTLRException, java.io.IOException
	{
		DtdPreprocessor p = new DtdPreprocessor();
		p.read(fileName);
		fileName = fileName+".PP.dtd";
		p.write(fileName);
		java.io.BufferedInputStream stream = new java.io.BufferedInputStream(
			new java.io.FileInputStream(fileName) );
		DtdLexer lexer = new DtdLexer( stream );
		DtdParser parser = new DtdParser( lexer );
		return parser.dtdFile();
	}


	private DtdContent parseContent( String code ) throws RecognitionException, TokenStreamException
	{
		java.io.ByteArrayInputStream stream = new java.io.ByteArrayInputStream(code.getBytes());
		DtdLexer lexer = new DtdLexer( stream );
		DtdParser parser = new DtdParser( lexer );
		parser.entities_.putAll(entities_);
		return parser.eCommaExpr();
	}


	private java.util.Vector parseAttribute( String code ) throws RecognitionException, TokenStreamException
	{
		code = code.trim();
		java.io.ByteArrayInputStream stream = new java.io.ByteArrayInputStream(code.getBytes());
		DtdLexer lexer = new DtdLexer( stream );
		DtdParser parser = new DtdParser( lexer );
		parser.entities_.putAll(entities_);
		java.util.Vector buffer = new java.util.Vector();
		while( parser.LA(1)!=EOF )
		{
			DtdAttribute attr = parser.attributeDecl();
			buffer.add(attr);
		}
		return buffer;
	}


	/**
	 * Stores names and values of entities.
	 */
	private java.util.HashMap entities_ = new java.util.HashMap();

protected DtdParser(TokenBuffer tokenBuf, int k) {
  super(tokenBuf,k);
  tokenNames = _tokenNames;
}

public DtdParser(TokenBuffer tokenBuf) {
  this(tokenBuf,2);
}

protected DtdParser(TokenStream lexer, int k) {
  super(lexer,k);
  tokenNames = _tokenNames;
}

public DtdParser(TokenStream lexer) {
  this(lexer,2);
}

public DtdParser(ParserSharedInputState state) {
  super(state,2);
  tokenNames = _tokenNames;
}

	public final DtdFile  dtdFile() throws RecognitionException, TokenStreamException {
		DtdFile p_file;
		
		
			entities_.put("amp",  "&" );
			entities_.put("lt",   "<" );
			entities_.put("gt",   ">" );
			entities_.put("quot", "\"");
			entities_.put("apos", "\'");
			//
			p_file=new DtdFile();
			DtdElement p_element=null;
			DtdAttributes p_attributes=null;
			DtdEntity p_entity=null;
			DtdNotation p_notation=null;
		
		
		try {      // for error handling
			{
			_loop3:
			do {
				switch ( LA(1)) {
				case ELEMENT_TOKEN:
				{
					p_element=element();
					p_file.addElement(p_element);
					break;
				}
				case ATTLIST_TOKEN:
				{
					p_attributes=attlist();
					p_file.addAttributes(p_attributes);
					break;
				}
				case ENTITY_TOKEN:
				{
					p_entity=entity();
					
						if( p_entity!=null )
						{
								String p_name = p_entity.getName();
								if( entities_.containsKey(p_name) )
								{
									throw new RecognitionException("entity redefinition: "+p_name);
								}
								entities_.put(p_name,p_entity.getValue());
								p_file.addEntity(p_entity);
							}
						
					break;
				}
				case NOTATION_TOKEN:
				{
					p_notation=notation();
					p_file.addNotation(p_notation);
					break;
				}
				default:
				{
					break _loop3;
				}
				}
			} while (true);
			}
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_0);
		}
		return p_file;
	}
	
	public final DtdElement  element() throws RecognitionException, TokenStreamException {
		DtdElement p_element=null;
		
		
			String p_name=null;
			DtdContent p_content=null;
		
		
		try {      // for error handling
			match(ELEMENT_TOKEN);
			p_name=eName();
			p_content=eContent();
			match(END_TOKEN);
			p_element=new DtdElement(p_name,p_content);
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_1);
		}
		return p_element;
	}
	
	public final DtdAttributes  attlist() throws RecognitionException, TokenStreamException {
		DtdAttributes p_attributes=null;
		
		
			String p_name=null;
			java.util.Vector p_buffer=new java.util.Vector(), p_result=null;
			DtdAttribute p_attr=null;
		
		
		try {      // for error handling
			match(ATTLIST_TOKEN);
			p_name=eName();
			{
			int _cnt31=0;
			_loop31:
			do {
				switch ( LA(1)) {
				case NAME:
				{
					p_attr=attributeDecl();
					p_buffer.add(p_attr);
					break;
				}
				case AND:
				case PERC:
				{
					p_result=entityAttributeRef();
					p_buffer.addAll(p_result);
					break;
				}
				default:
				{
					if ( _cnt31>=1 ) { break _loop31; } else {throw new NoViableAltException(LT(1), getFilename());}
				}
				}
				_cnt31++;
			} while (true);
			}
			match(END_TOKEN);
			p_attributes=new DtdAttributes(p_name,p_buffer);
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_1);
		}
		return p_attributes;
	}
	
	public final DtdEntity  entity() throws RecognitionException, TokenStreamException {
		DtdEntity p_entity=null;
		
		Token  n2 = null;
		
			boolean p_parameter=false, p_system=false;
			String p_ndata=null, p_name=null;
		
		
		try {      // for error handling
			match(ENTITY_TOKEN);
			{
			switch ( LA(1)) {
			case PERC:
			{
				match(PERC);
				p_parameter=true;
				break;
			}
			case NAME:
			{
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
			}
			p_name=eName();
			{
			switch ( LA(1)) {
			case LITERAL_SYSTEM:
			{
				match(LITERAL_SYSTEM);
				p_system=true;
				break;
			}
			case STRING:
			{
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
			}
			n2 = LT(1);
			match(STRING);
			{
			switch ( LA(1)) {
			case LITERAL_NDATA:
			{
				match(LITERAL_NDATA);
				p_ndata=eName();
				break;
			}
			case END_TOKEN:
			{
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
			}
			match(END_TOKEN);
			p_entity=new DtdEntity(p_name,n2.getText(),p_parameter,p_system,p_ndata);
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_1);
		}
		return p_entity;
	}
	
	public final DtdNotation  notation() throws RecognitionException, TokenStreamException {
		DtdNotation p_notation=null;
		
		Token  n2 = null;
		
			String p_name=null;
		
		
		try {      // for error handling
			match(NOTATION_TOKEN);
			p_name=eName();
			match(LITERAL_SYSTEM);
			n2 = LT(1);
			match(STRING);
			match(END_TOKEN);
			p_notation=new DtdNotation(p_name,n2.getText());
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_1);
		}
		return p_notation;
	}
	
	public final String  eName() throws RecognitionException, TokenStreamException {
		String p_name=null;
		
		Token  n1 = null;
		Token  n2 = null;
		
		try {      // for error handling
			n1 = LT(1);
			match(NAME);
			p_name=n1.getText();
			{
			_loop7:
			do {
				if ((LA(1)==COLON)) {
					match(COLON);
					n2 = LT(1);
					match(NAME);
					p_name+=":"+n2.getText();
				}
				else {
					break _loop7;
				}
				
			} while (true);
			}
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_2);
		}
		return p_name;
	}
	
	public final DtdContent  eContent() throws RecognitionException, TokenStreamException {
		DtdContent p_content=null;
		
		
		try {      // for error handling
			switch ( LA(1)) {
			case LITERAL_ANY:
			{
				match(LITERAL_ANY);
				p_content=DtdConstant.ANY;
				break;
			}
			case LITERAL_EMPTY:
			{
				match(LITERAL_EMPTY);
				p_content=DtdConstant.EMPTY;
				break;
			}
			case LPAREN:
			{
				p_content=eRule();
				break;
			}
			case AND:
			case PERC:
			{
				p_content=entityContentRef();
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_3);
		}
		return p_content;
	}
	
	public final DtdContent  eRule() throws RecognitionException, TokenStreamException {
		DtdContent p_content=null;
		
		
			String p_Opt=null;
		
		
		try {      // for error handling
			match(LPAREN);
			p_content=eCommaExpr();
			match(RPAREN);
			{
			switch ( LA(1)) {
			case QUEST:
			case PLUS:
			case STAR:
			{
				p_Opt=eOpt();
				break;
			}
			case END_TOKEN:
			case RPAREN:
			case COMMA:
			case BAR:
			{
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
			}
			p_content.mergeOptionally(p_Opt);
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_4);
		}
		return p_content;
	}
	
	public final DtdContent  entityContentRef() throws RecognitionException, TokenStreamException {
		DtdContent p_content=null;
		
		
			String p_name=null;
		
		
		try {      // for error handling
			{
			switch ( LA(1)) {
			case AND:
			{
				match(AND);
				break;
			}
			case PERC:
			{
				match(PERC);
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
			}
			p_name=eName();
			match(SEMICOL);
			
				String p_value=(String)entities_.get(p_name);
				if( p_value==null )
				{
					throw new RecognitionException("unknown entity: "+p_name);
				}
				p_content = parseContent(p_value);
			
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_4);
		}
		return p_content;
	}
	
	public final DtdContent  eCommaExpr() throws RecognitionException, TokenStreamException {
		DtdContent p_content=null;
		
		
			DtdContent p_expr=null;
		
		
		try {      // for error handling
			p_content=eBarExpr();
			{
			_loop13:
			do {
				if ((LA(1)==COMMA) && (_tokenSet_5.member(LA(2)))) {
					match(COMMA);
					p_expr=eCommaExpr();
					p_content=new DtdComma(p_content,p_expr);
				}
				else {
					break _loop13;
				}
				
			} while (true);
			}
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_6);
		}
		return p_content;
	}
	
	public final String  eOpt() throws RecognitionException, TokenStreamException {
		String p_opt=null;
		
		
		try {      // for error handling
			switch ( LA(1)) {
			case QUEST:
			{
				match(QUEST);
				p_opt="?";
				break;
			}
			case PLUS:
			{
				match(PLUS);
				p_opt="+";
				break;
			}
			case STAR:
			{
				match(STAR);
				p_opt="*";
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_4);
		}
		return p_opt;
	}
	
	public final DtdContent  eBarExpr() throws RecognitionException, TokenStreamException {
		DtdContent p_content=null;
		
		
			DtdContent p_expr=null;
		
		
		try {      // for error handling
			p_content=eSimpleExpr();
			{
			_loop16:
			do {
				if ((LA(1)==BAR) && (_tokenSet_5.member(LA(2)))) {
					match(BAR);
					p_expr=eBarExpr();
					p_content=new DtdBar(p_content,p_expr);
				}
				else {
					break _loop16;
				}
				
			} while (true);
			}
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_7);
		}
		return p_content;
	}
	
	public final DtdContent  eSimpleExpr() throws RecognitionException, TokenStreamException {
		DtdContent p_content=null;
		
		
			String p_name=null, p_Opt=null;
		
		
		try {      // for error handling
			switch ( LA(1)) {
			case PCDATA_TOKEN:
			{
				match(PCDATA_TOKEN);
				p_content=DtdConstant.getPCDATA();
				break;
			}
			case NAME:
			{
				p_name=eName();
				{
				switch ( LA(1)) {
				case QUEST:
				case PLUS:
				case STAR:
				{
					p_Opt=eOpt();
					break;
				}
				case RPAREN:
				case COMMA:
				case BAR:
				{
					break;
				}
				default:
				{
					throw new NoViableAltException(LT(1), getFilename());
				}
				}
				}
				p_content=new DtdName(p_name); p_content.mergeOptionally(p_Opt);
				break;
			}
			case LPAREN:
			{
				p_content=eRule();
				break;
			}
			case AND:
			case PERC:
			{
				p_content=entityContentRef();
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_7);
		}
		return p_content;
	}
	
	public final java.util.Vector  entityAttributeRef() throws RecognitionException, TokenStreamException {
		java.util.Vector p_attr=null;
		
		
			String p_name=null;
		
		
		try {      // for error handling
			{
			switch ( LA(1)) {
			case AND:
			{
				match(AND);
				break;
			}
			case PERC:
			{
				match(PERC);
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
			}
			p_name=eName();
			match(SEMICOL);
			
				String p_value=(String)entities_.get(p_name);
				if( p_value==null )
				{
					throw new RecognitionException("unknown entity: "+p_name);
				}
				p_attr = parseAttribute(p_value);
			
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_8);
		}
		return p_attr;
	}
	
	public final DtdAttribute  attributeDecl() throws RecognitionException, TokenStreamException {
		DtdAttribute p_attr=null;
		
		
			DtdAttributeType p_type=null;
			DtdAttributeDefault p_default=null;
			String p_name=null;
		
		
		try {      // for error handling
			{
			p_name=eName();
			p_type=typeDecl();
			p_default=defaultDecl();
			}
			p_attr=new DtdAttribute(p_name,p_type,p_default);
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_8);
		}
		return p_attr;
	}
	
	public final DtdAttributeType  typeDecl() throws RecognitionException, TokenStreamException {
		DtdAttributeType p_type=null;
		
		
			boolean p_notation=false;
			DtdEnumeration p_enum=null;
		
		
		try {      // for error handling
			switch ( LA(1)) {
			case LITERAL_CDATA:
			{
				match(LITERAL_CDATA);
				p_type=DtdAttributeType.CDATA;
				break;
			}
			case LITERAL_ENTITY:
			{
				match(LITERAL_ENTITY);
				p_type=DtdAttributeType.ENTITY;
				break;
			}
			case LITERAL_ENTITIES:
			{
				match(LITERAL_ENTITIES);
				p_type=DtdAttributeType.ENTITIES;
				break;
			}
			case LITERAL_ID:
			{
				match(LITERAL_ID);
				p_type=DtdAttributeType.ID;
				break;
			}
			case LITERAL_IDREF:
			{
				match(LITERAL_IDREF);
				p_type=DtdAttributeType.IDREF;
				break;
			}
			case LITERAL_IDREFS:
			{
				match(LITERAL_IDREFS);
				p_type=DtdAttributeType.IDREFS;
				break;
			}
			case LITERAL_NMTOKEN:
			{
				match(LITERAL_NMTOKEN);
				p_type=DtdAttributeType.NMTOKEN;
				break;
			}
			case LITERAL_NMTOKENS:
			{
				match(LITERAL_NMTOKENS);
				p_type=DtdAttributeType.NMTOKENS;
				break;
			}
			case LPAREN:
			case LITERAL_NOTATION:
			{
				{
				switch ( LA(1)) {
				case LITERAL_NOTATION:
				{
					match(LITERAL_NOTATION);
					p_notation=true;
					break;
				}
				case LPAREN:
				{
					break;
				}
				default:
				{
					throw new NoViableAltException(LT(1), getFilename());
				}
				}
				}
				p_enum=enumDecl();
				p_type=new DtdAttributeTypeEnumeration(p_enum,p_notation);
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_9);
		}
		return p_type;
	}
	
	public final DtdAttributeDefault  defaultDecl() throws RecognitionException, TokenStreamException {
		DtdAttributeDefault p_default=null;
		
		Token  n1 = null;
		
			boolean p_fixed=false;
		
		
		try {      // for error handling
			switch ( LA(1)) {
			case REQUIRED_TOKEN:
			{
				match(REQUIRED_TOKEN);
				p_default=DtdAttributeDefault.REQUIRED;
				break;
			}
			case IMPLIED_TOKEN:
			{
				match(IMPLIED_TOKEN);
				p_default=DtdAttributeDefault.IMPLIED;
				break;
			}
			case STRING:
			case FIXED_TOKEN:
			{
				{
				switch ( LA(1)) {
				case FIXED_TOKEN:
				{
					match(FIXED_TOKEN);
					p_fixed=true;
					break;
				}
				case STRING:
				{
					break;
				}
				default:
				{
					throw new NoViableAltException(LT(1), getFilename());
				}
				}
				}
				n1 = LT(1);
				match(STRING);
				p_default=p_fixed ? DtdAttributeDefault.createFixed(n1.getText()) : DtdAttributeDefault.createDefault(n1.getText());
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_8);
		}
		return p_default;
	}
	
	public final DtdEnumeration  enumDecl() throws RecognitionException, TokenStreamException {
		DtdEnumeration p_enum=null;
		
		Token  n1 = null;
		Token  n2 = null;
		
			java.util.Vector p_buffer = new java.util.Vector();
		
		
		try {      // for error handling
			match(LPAREN);
			n1 = LT(1);
			match(NAME);
			p_buffer.add(n1.getText());
			{
			_loop38:
			do {
				if ((LA(1)==BAR)) {
					match(BAR);
					n2 = LT(1);
					match(NAME);
					p_buffer.add(n2.getText());
				}
				else {
					break _loop38;
				}
				
			} while (true);
			}
			match(RPAREN);
			p_enum=new DtdEnumeration(p_buffer);
		}
		catch (RecognitionException ex) {
			reportError(ex);
			consume();
			consumeUntil(_tokenSet_9);
		}
		return p_enum;
	}
	
	
	public static final String[] _tokenNames = {
		"<0>",
		"EOF",
		"<2>",
		"NULL_TREE_LOOKAHEAD",
		"ELEMENT_TOKEN",
		"END_TOKEN",
		"NAME",
		"COLON",
		"\"ANY\"",
		"\"EMPTY\"",
		"LPAREN",
		"RPAREN",
		"COMMA",
		"BAR",
		"PCDATA_TOKEN",
		"AND",
		"PERC",
		"SEMICOL",
		"QUEST",
		"PLUS",
		"STAR",
		"ENTITY_TOKEN",
		"\"SYSTEM\"",
		"STRING",
		"\"NDATA\"",
		"NOTATION_TOKEN",
		"ATTLIST_TOKEN",
		"\"CDATA\"",
		"\"ENTITY\"",
		"\"ENTITIES\"",
		"\"ID\"",
		"\"IDREF\"",
		"\"IDREFS\"",
		"\"NMTOKEN\"",
		"\"NMTOKENS\"",
		"\"NOTATION\"",
		"REQUIRED_TOKEN",
		"IMPLIED_TOKEN",
		"FIXED_TOKEN",
		"WS",
		"NAME_CHAR",
		"NewlineProcessing",
		"String1",
		"String2",
		"COMMENT_DATA",
		"COMMENT"
	};
	
	private static final long[] mk_tokenSet_0() {
		long[] data = { 2L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_0 = new BitSet(mk_tokenSet_0());
	private static final long[] mk_tokenSet_1() {
		long[] data = { 102760466L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_1 = new BitSet(mk_tokenSet_1());
	private static final long[] mk_tokenSet_2() {
		long[] data = { 68599922528L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_2 = new BitSet(mk_tokenSet_2());
	private static final long[] mk_tokenSet_3() {
		long[] data = { 32L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_3 = new BitSet(mk_tokenSet_3());
	private static final long[] mk_tokenSet_4() {
		long[] data = { 14368L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_4 = new BitSet(mk_tokenSet_4());
	private static final long[] mk_tokenSet_5() {
		long[] data = { 115776L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_5 = new BitSet(mk_tokenSet_5());
	private static final long[] mk_tokenSet_6() {
		long[] data = { 6144L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_6 = new BitSet(mk_tokenSet_6());
	private static final long[] mk_tokenSet_7() {
		long[] data = { 14336L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_7 = new BitSet(mk_tokenSet_7());
	private static final long[] mk_tokenSet_8() {
		long[] data = { 98400L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_8 = new BitSet(mk_tokenSet_8());
	private static final long[] mk_tokenSet_9() {
		long[] data = { 481044725760L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_9 = new BitSet(mk_tokenSet_9());
	
	}
